---
layout: post
title: Oracle autonomous health framework 19
published: false
---

Oracle Autonomous Health Framework is now delivered as a separate tool whith its own lifecycle. It brings a lot of functionalities but it is difficult to get started as the documentation is not always consistent and the tool might not be completly mature.
<!--more-->

## Install and basic commands

Download the zip file from metalink, unzip it and run the setup with user root

```bash
ahf_setup -ahf_loc /opt/oracle.ahf -data_dir /oraapp01/oracle.ahf/data
```

* If root ssh access is not possible between the nodes then you must do the install on each nodes.
* it is always possible to redo a failed install by first de-installing with tfactl uninstall.
* after install tfa will do an inventory, wait for it to be complete (see with tfactl status). In some case I had to restart tfa on one node in order to have the status ok on both nodes.

```bash
root@ora01 stage]# tfactl status

.---------------------------------------------------------------------------------------------.
| Host  | Status of TFA | PID   | Port | Version    | Build ID             | Inventory Status |
+-------+---------------+-------+------+------------+----------------------+------------------+
| ora01 | RUNNING       | 12974 | 5000 | 20.1.3.0.0 | 20130020200429095054 | RUNNING          |
| ora02 | RUNNING       | 11764 | 5000 | 20.1.3.0.0 | 20130020200429095054 | RUNNING          |
'-------+---------------+-------+------+------------+----------------------+------------------'

```

```bash
[root@ora01 stage]# tfactl print actions
TFA-00103 TFA is not yet secured to run all commands

TFA has not synchronised across all nodes yet. 
If an install or upgrade is in progress and the operation has not completed on all 
nodes then please wait for completion and allow TFA 10 minutes to synchronize.  
If no install or upgrade is in progress or you need TFA to synchronize now 
Please run 'tfactl syncnodes' to generate and copy TFA Certificates.


[root@ora02 stage]# tfactl status

.---------------------------------------------------------------------------------------------.
| Host  | Status of TFA | PID   | Port | Version    | Build ID             | Inventory Status |
+-------+---------------+-------+------+------------+----------------------+------------------+
| ora02 | RUNNING       | 19919 | 5000 | 20.1.3.0.0 | 20130020200429095054 | COMPLETE         |
| ora01 | NOT RUNNING   | -     |      |            |                      |                  |
'-------+---------------+-------+------+------------+----------------------+------------------'

[root@ora01 stage]# tfactl restart
TFA-00002 Oracle Trace File Analyzer (TFA) is not running
Starting TFA..
Waiting up to 100 seconds for TFA to be started..
. . . . . 
Successfully started TFA Process..
. . . . . 
TFA Started and listening for commands
[root@ora01 stage]# tfactl status

.---------------------------------------------------------------------------------------------.
| Host  | Status of TFA | PID   | Port | Version    | Build ID             | Inventory Status |
+-------+---------------+-------+------+------------+----------------------+------------------+
| ora01 | RUNNING       | 27211 | 5000 | 20.1.3.0.0 | 20130020200429095054 | COMPLETE         |
| ora02 | RUNNING       | 19919 | 5000 | 20.1.3.0.0 | 20130020200429095054 | COMPLETE         |
'-------+---------------+-------+------+------------+----------------------+------------------'
```

## Orachk

```bash
orachk -d info
```

shows that the scheduler used is TFA (not the legacy orachk scheduler). This means that we must not run -initsetup (this is for the legacy scheduler).

tfa is started by a systemd unit called oracle-tfa.services

```bash
root@ora01 oracle.ahf]# orachk -d status
orachk is using TFA Scheduler. TFA PID: 13181
```

```bash
systemctl status oracle-tfa
journalctl --unit oracle-tfa
ps -ef | grep tfa
```

After install we have a few profiles created for us, profile daemon_autostart make sure a discovery is done daily at 1, so that the other one can use the discovery. The autostart_client will do a full orach (using the discovery), it will log some json results to syslog also.

Those profiles can be removed and recreated with orachk -autostop and orachk -autostart. Some profiles have the -usediscovery flag and so they will not work if a discovery was not done before. One can do a discovery manually with orachk -discovery. 


```bash
root@ora01 stage]# tfactl orachk -get all
------------------------------------------------------------
ID: orachk.autostart_discovery
------------------------------------------------------------
AUTORUN_FLAGS  =  -silentforce -rediscovery
AUTORUN_SCHEDULE  =  43 12 3 5 *
------------------------------------------------------------
------------------------------------------------------------
ID: orachk.daemon_autostart
------------------------------------------------------------
AUTORUN_FLAGS  =  -silentforce -rediscovery
AUTORUN_SCHEDULE  =  0 1 * * *
------------------------------------------------------------
------------------------------------------------------------
ID: orachk.autostart_client_oratier1
------------------------------------------------------------
AUTORUN_FLAGS  =  -usediscovery -profile oratier1 -syslog -dball -showpass -tag autostart_client_oratier1
COLLECTION_RETENTION  =  7
AUTORUN_SCHEDULE  =  0 2 * * *
------------------------------------------------------------
------------------------------------------------------------
ID: orachk.autostart_client
------------------------------------------------------------
AUTORUN_FLAGS  =  -usediscovery -syslog -tag autostart_client
COLLECTION_RETENTION  =  14
AUTORUN_SCHEDULE  =  0 3 * * 0
------------------------------------------------------------
```

```bash
orachk -d nextautorun
orachk -set "AUTORUN_SCHEDULE=0 11 * * 0" -id autostart_client
orachk -get all
```

Note: maybe it is a bug but on one system orachk will not run a -discovery in silentmode, unless the RAT_CRS_HOME env variable is set. As a consequence the default profile that does the rediscovery actually delete the discovery without creating a new one. My work-around was to disable the rediscovery and do it via cron (setting the RAT_CRS_HOME in the script).

### Manual run of orach

first do a discovery

```bash
orachk -discovery
```

then do a run. Use screen or nohup (with -silentforce in this case) because it takes very long. Take care that sometimes orachk prompts for RAT_CRS_HOME (not sure why because it finds the CRS home perfectly).

```bash
orachk -usediscovery
```

## Uploading results in a database

```sql
create user ORACHKCM identified by orachk2020 default tablespace users ;      
grant create session,connect to orachkcm;
alter user orachkcm quota unlimited on users;
connect orachkcm/orachk2020
CREATE TABLE RCA13_DOCS (
    DOC_ID          NUMBER DEFAULT to_number(sys_guid(),'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX') NOT NULL ENABLE,
    COLLECTION_ID   VARCHAR2(40 BYTE),
    FILENAME        VARCHAR2(1000 BYTE) NOT NULL ENABLE,
    FILE_MIMETYPE   VARCHAR2(512 BYTE),
    FILE_CHARSET    VARCHAR2(512 BYTE),
    FILE_BLOB       BLOB NOT NULL ENABLE,
    FILE_COMMENTS   VARCHAR2(4000 BYTE),
    TAGS            VARCHAR2(4000 BYTE),
    ATTR1           VARCHAR2(200 BYTE),
    UPLOADED_BY     VARCHAR2(200 BYTE) DEFAULT USER,
    UPLOADED_ON     TIMESTAMP (6) DEFAULT systimestamp,
    SR_BUG_NUM      VARCHAR2(20 BYTE),
    CONSTRAINT RCA13_DOCS_PK PRIMARY KEY (DOC_ID),
    CONSTRAINT RCA13_DOCS_UK1 UNIQUE (FILENAME)
  );

CREATE TABLE auditcheck_result (
     COLLECTION_DATE          TIMESTAMP NOT NULL ENABLE,
     CHECK_NAME               VARCHAR2(256),
     PARAM_NAME               VARCHAR2(256),
     STATUS                   VARCHAR2(256),
     STATUS_MESSAGE           VARCHAR2(256),
     ACTUAL_VALUE             VARCHAR2(256),
     RECOMMENDED_VALUE        VARCHAR2(256),
     COMPARISON_OPERATOR      VARCHAR2(256),
     HOSTNAME                 VARCHAR2(256),
     INSTANCE_NAME            VARCHAR2(256),
     CHECK_TYPE               VARCHAR2(256),
     DB_PLATFORM              VARCHAR2(256),
     OS_DISTRO                VARCHAR2(256),
     OS_KERNEL                VARCHAR2(256),
     OS_VERSION               NUMBER,
     DB_VERSION               VARCHAR2(256),
     CLUSTER_NAME             VARCHAR2(256),
     DB_NAME                  VARCHAR2(256),
     ERROR_TEXT               VARCHAR2(256),
     CHECK_ID                 VARCHAR2(40),
     NEEDS_RUNNING            VARCHAR2(100),
     MODULES                  VARCHAR2(4000),
     DATABASE_ROLE            VARCHAR2(100),
     CLUSTERWARE_VERSION      VARCHAR2(100),
     GLOBAL_NAME              VARCHAR2(256),
     UPLOAD_COLLECTION_NAME   VARCHAR2(256) NOT NULL ENABLE,
     AUDITCHECK_RESULT_ID     VARCHAR2(256) DEFAULT sys_guid() NOT NULL ENABLE,
     COLLECTION_ID            VARCHAR2(40),
     TARGET_TYPE              VARCHAR2(128),
     TARGET_VALUE             VARCHAR2(256),
     CONSTRAINT "AUDITCHECK_RESULT_PK" PRIMARY KEY ("AUDITCHECK_RESULT_ID")
);

CREATE TABLE  auditcheck_patch_result (
       COLLECTION_DATE         TIMESTAMP(6) NOT NULL,
       HOSTNAME                VARCHAR2(256),
       ORACLE_HOME_TYPE        VARCHAR2(256),
       ORACLE_HOME_PATH        VARCHAR2(256),
       ORACLE_HOME_VERSION     VARCHAR2(256),
       PATCH_NUMBER            NUMBER,
       CLUSTER_NAME            VARCHAR2(256),
       DESCRIPTION             VARCHAR2(256),
       PATCH_TYPE              VARCHAR2(128),
       APPLIED                 NUMBER,
       UPLOAD_COLLECTION_NAME  VARCHAR2(256),
       RECOMMENDED             NUMBER
);
```

To upload results manually in auditcheck tables, from a past run

```bash
sqlplus orachkcm/orachk2020@"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=orarac01-scan.localnet)(PORT=1531))(CONNECT_DATA=(SERVICE_NAME=POCDEV1BE.localnet)(SERVER=DEDICATED)))"
set define off
@upload_orachk_patch_result.sql
@upload_orachk_result_base.sql
@upload_orachk_result.sql
```

Automate the upload of the result

The following will load the zip file in table rca13_docs

```bash
orachk -setdbupload all
```

To have the results stored in a usable way for custom apps, we can also have it loaded in the auditcheck tables

```bash
orachk -setdbupload RAT_UPLOAD_TABLE,RAT_PATCH_UPLOAD_TABLE
```

```text
Enter value for RAT_UPLOAD_TABLE: auditcheck_result


Enter value for RAT_PATCH_UPLOAD_TABLE: auditcheck_patch_result

Database upload parameters successfully stored in orachk wallet. Run will keep uploading the collections in database until it is unset using ./orachk -unsetdbupload all/<environment variable name>
```

Unfortunately the tables auditcheck_result and auditcheck_patch_result are not automatically loaded at the end of run, but the zip file is loaded in the rca13_docs

### orachk json

orachk send some json output in syslog, I guess this could be used by a monitoring tool like ELK

```bash
journalctl --since 09:10:00 --output=json-pretty --unit=oracle-tfa
```

the json files are also in the directory upload.



## tfactl

tfactl status

tfactl toolstatus

tfactl summary

tfactl managelogs -purge -older 3d -dryrun

tfactl print config

It looks like oracle finally has a way to maintain all the log files easily. Although I am sure the audit files will still need to be manually deleted...

```bash 
tfactl set manageLogsAutoPurgePolicyAge=10d

tfactl get manageLogsAutoPurge
tfactl set manageLogsAutoPurge=ON
```


## REST

tfactl rest

curl --insecure --user tfarest:TFAAdmin#1 https://ora01.localnet:9090/ords/tfactl/print/status

